{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "টেন্সরফ্লো ২.০ ও কেরাস পরিচিতি পর্ব - ৪ [ ইমেজ ডাটা লোড করা ].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/menon92/DL-Sneak-Peek/blob/master/%E0%A6%9F%E0%A7%87%E0%A6%A8%E0%A7%8D%E0%A6%B8%E0%A6%B0%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A7%8B_%E0%A7%A8_%E0%A7%A6_%E0%A6%93_%E0%A6%95%E0%A7%87%E0%A6%B0%E0%A6%BE%E0%A6%B8_%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%9A%E0%A6%BF%E0%A6%A4%E0%A6%BF_%E0%A6%AA%E0%A6%B0%E0%A7%8D%E0%A6%AC_%E0%A7%AA_%5B_%E0%A6%87%E0%A6%AE%E0%A7%87%E0%A6%9C_%E0%A6%A1%E0%A6%BE%E0%A6%9F%E0%A6%BE_%E0%A6%B2%E0%A7%8B%E0%A6%A1_%E0%A6%95%E0%A6%B0%E0%A6%BE_%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oxw4WahM7DU9"
      },
      "source": [
        "# ইমেজ ডাটা \n",
        "\n",
        "এখানে আমরা দেখব ডিপলার্নিং মডেল ট্রেনিং করার আগে ডাটা লোডিং পাইপলাইন কিভাবে করা হয় । এইজন্য ডাটাসেট হিসাবে ব্যাবহার করব \n",
        "<a herf=\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"> flower photos</a>। এটা 218 MB সাইজের একটা ডাটাসেট। এই ডাটাসেট ব্যাবহার করে আমরা নিচের বিষয়গুলো কভার করার চেষ্টা করব । \n",
        "\n",
        "* `tf.keras.preprocessing.image.ImageDataGenerator` দিয়ে কিভাবে ইমেজ ডাটা লোড করা যায় । \n",
        "* `tf.data` দিয়ে কিভাবে ইমেজ ডাটা লোড করা যায় । \n",
        "* উপরের দুইটার কোনটাতে কি সুবিধা পাওয়া যাবে । \n",
        "* কোনটাতে কেমন সময় লাবে । "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hoQQiZDB6URn"
      },
      "source": [
        "### প্রয়োজনীয় প্যাকেজ ইম্পোট করে নেই "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OCsDHOTDLUzt",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version এই কমান্ড কেবলমাত্র colab এ কাজ করে লোকাল নোটবুকে কাজ করবে না । \n",
        "  # এই জন্য try except ব্যাবহার করা হয়েছে । \n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KT6CcaqgQewg",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gIksPgtT8B6B",
        "colab": {}
      },
      "source": [
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZJ20R66fzktl",
        "colab": {}
      },
      "source": [
        "# টেন্সফ্লো ভার্সন চেক করে নিন \n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wO0InzL66URu"
      },
      "source": [
        "### ডাটাসেট ডাউনলোড \n",
        "\n",
        "ডাটাসেট ডাউনলোড করার জন্য আমরা `tf.keras.utils.get_file` এই ফাংশন ব্যাবহার করব । এখানে আমরা ডাটাসেট url এবং কি নামের (`fname='flower_photos'`) ফোল্ডারে ডাউনলোড হয়ে জমা হবে সেটা বলে দিচ্ছি । এবং `flower_photos.tgz` যেহেতু একটা জিপ ফাইল তাই এটাকে আনজিপ করার জন্য আমরা `untar=True` দিয়ে দিব । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rN-Pc6Zd6awg",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "\n",
        "DATASET_URL = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "\n",
        "data_dir = tf.keras.utils.get_file(origin=DATASET_URL, fname='flower_photos', untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "print('Dataset directory:', data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9GH7aRSrU8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo  apt -qq install tree\n",
        "!tree -L 1 /root/.keras/datasets/flower_photos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udV-b8tlrU9L",
        "colab_type": "text"
      },
      "source": [
        "আমরা দেখতে পাচ্ছি যে ৫ টা আলাদা আলাদা ফুলের ফোল্ডার আছে এবং একটা টেক্সট ফাইল আছে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QhewYCxhXQBX",
        "colab": {}
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "image_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqhCCLdgrU9W",
        "colab_type": "text"
      },
      "source": [
        "আমরা দেখতে পাচ্ছি যে সব মিলে ৩৬৭০ টা ফুলের ছবি আছে । এখন আমরা দেখব যে কোন ফুল কয়টা করে আছে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QydXDtQrU9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLOWERS = ['daisy', 'dandelion', 'roses','sunflowers','tulips']\n",
        "for flower in FLOWERS:\n",
        "    total_flower = len(list(data_dir.glob(flower + \"/*.jpg\")))\n",
        "    print(\"`{:10s}` folder contain {} flower images\".format(flower, total_flower))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IVxsk4OW61TY"
      },
      "source": [
        "আমরা কিছু ৩ টা টিউলিপ ফুল প্লট করে দেখি । আমরা প্রত্যেকটা ফুলের ছবির সাথে তাদের সাইজ প্রিন্ট করেছি । এবং আমরা দেখতে পাচ্ছি যে এক একটা ছবির সাইজ এক এক রকম । আমাদের মডেলে ডটা ফিট করার আগে অবশ্যই সব ছবিকে একটা ফিক্স সাইজে নিয়ে আসতে হবে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "crs7ZjEp60Ot",
        "colab": {}
      },
      "source": [
        "roses = list(data_dir.glob('tulips/*'))\n",
        "\n",
        "for image_path in roses[:3]:\n",
        "    image = Image.open(str(image_path))\n",
        "    print('image size', image.size)\n",
        "    display.display(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6jobDTUs8Wxu"
      },
      "source": [
        "## `keras.preprocessing` দিয়ে ইমেজ ডাটা লোড করা"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehhW308g8soJ"
      },
      "source": [
        "আমরা <a herf=\"https://keras.io/preprocessing/image/\"> ImageDataGenerator </a> ব্যাবহার করে খুব সহজেই ইমেজ লোড করতে পারি । `rescale=1./255` দিয়ে আমরা বলে দিচ্ছি ইমেজের পিক্সেল ভেলু গুলোকে [0,255] থেকে [0,1] মাঝে নিয়ে আসা ।  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "syDdF_LWVrWE",
        "colab": {}
      },
      "source": [
        "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lAmtzsnjDNhB"
      },
      "source": [
        "ইমেজ ডাটা লোড করার জন্য আমরা কিছু প্যারামিটার ডিফাইন করি । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1zf695or-Flq",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tto0eL7rU-O",
        "colab_type": "text"
      },
      "source": [
        "এখন আমরা ডাটা ডিরেক্টরি থেকে ৫ টা ক্লাসের নাম বের করে ফেলি ।   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSey7QgKrU-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "CLASS_NAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pw94ajOOVrWI",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_generator.flow_from_directory(\n",
        "    directory=str(data_dir),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='rgb', # one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". \n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    classes = list(CLASS_NAMES),\n",
        "    class_mode='categorical' # \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\".\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z5Mm3oarU-n",
        "colab_type": "text"
      },
      "source": [
        "আমরা যেহেতু ইমেজ ডিরেক্টরি থেকে ডাটা লোড করব এইজন্য `flow_from_directory` করেছি । পাণ্ডা ডাটা ফ্রেম থেকে লোড করতে হলে `flow_from_dataframe` ব্যাবহার করতে হবে । আপনি `flow_from_directory` এর ফুল ফাংশন ডেফিনেসন এই থেকে দেখে নিতে পারেন । উপরে যে প্যারামিটার ব্যাবহার করা হয়েছে তার কোনটা কি কাজ করছে সটা নিচে দেয়া হল । \n",
        "\n",
        "- `directory` ৫ টা ফুলের ডিরেক্টরি যেটা সেটা এখানে দিতে হবে । \n",
        "- `batch_size` প্রতিবার কয়টা করে ছবি প্রসেস করে রিটার্ন করবে সেটা বলে দিচ্ছি । \n",
        "- `color_mode` ছবি সাদাকালো না রঙ্গিন সেটা বলে দিচ্ছি । \n",
        "- `shuffle` ডাটা কি প্রতিবার সাফল হবে কি না সেটা বলে দিচ্ছি । \n",
        "- `target_size` আমরা আগে দেখেছিলাম এক একটা ছবির সাইজ এক এক রকম । সেটা ফিক্স একটা সাইজে নিয়ে আসার জন্য টার্গেট সাইজ বলে দিচ্ছি । \n",
        "- `classes` ক্লাসের নাম লিস্ট আকারে দিতে হবে । \n",
        "- `class_mode='cagegorical'` যেহেতু আমাদের লেবেল ওয়ান হট চাই এই জন্য cagegorical ব্যাবহার করেছি + আমাদের ডাটা ক্যাটাগরিকেল ডাটা। "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84qgLJ7xrU-p",
        "colab_type": "text"
      },
      "source": [
        "## One-Hot এনকোডিং কি \n",
        "\n",
        "মনে করা আপনার ৩ টা ক্লাস আছে । ক্লাস গুলো হল A, B, C এই তিনটার লেবেল যথাক্রমে 0, 1, 2 । এখন A এর লেবেল 0 কে আমরা যদি one-hot এনকোডিং এ রিপ্রেজেন্ট করতে চাই তাহলে লিখতে হবে । `label of A = [1, 0, 0]`, `label of B = [0, 1, 0]`, `label of C = [0, 0, 1]` \n",
        "\n",
        "এখানে লক্ষণীয়ে যে আমরা যে লিস্ট লেখেছি তার সাইজ ৩ । কারণ আমার মোট ক্লাস ৩ আমাদের যদি ৫ টা ক্লাস থাকে তাহলে সাইজ হবে ৫ অর্থাৎ ক্লাস n হলে সাইজ n হবে । আর একটা বিষয় লক্ষণীয় যে আমাদের লেবেলের মান যত আমরা লিস্টের তত তম ইনডেক্সের মান ১ করে দিয়েছি এবং বাকি ইনডেক্সগুলো মান ০ সেট করে দিয়েছি । \n",
        "\n",
        "যখন কোন লেবেল কে এই ভাবে রিপ্রেজেন্ট করা হয় তখন তাকে বলা হয় One-Hot এনকোডিং । এখন প্রশ্ন হল এটা কেন করা হয় ? এটা করা হয় কারণ মডেল ট্রেনিং করার সময় যখন `crossentropy` লস হিসাবে করা হয় তখন লেবেল যদি One-Hot এনকোডিং ফরমেটে থাকে তাহলে লস কম্পিউটেশন খুব দ্রুত হয় । কেন দ্রুত হয় সেটা বুঝতে হলে আপনাকে `crossentropy` কিভাবে কাজ করে সেটা বুঝতে হবে । এই জন্য আপনি <a href=\"https://www.youtube.com/watch?v=tRsSi_sqXjI\"> Cross Entropy</a> এই  ভিডিও দেখতে পারেন । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKafWs0oOjs3",
        "colab": {}
      },
      "source": [
        "# take batch image using `next`\n",
        "image_batch, label_batch = next(train_data_gen)\n",
        "\n",
        "for image, label in zip(image_batch[:3], label_batch[:3]):\n",
        "    print('image shape', image.shape, ' one hot label', label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ZgIZeXaDUsF"
      },
      "source": [
        "এখন আমরা দেখতে পাচ্ছি যে ছবিগুলো আমাদের দেয় সাইজে কনভার্ট হয়ে গিয়েছে এবং এবং লেবেল টা one-hot এ কনভার্ট হয়ে গিয়েছে । এখন আমরা দেখব এটা ব্যাচ (৩২) যতগুলো ছবি আছে সবগুলো প্লট করে দেখি । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLp0XVG_Vgi2",
        "colab": {}
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for n in range(32):\n",
        "        ax = plt.subplot(4, 8, n+1)\n",
        "        plt.imshow(image_batch[n])\n",
        "        class_name = CLASS_NAMES[label_batch[n]==1][0].title()\n",
        "        plt.title(class_name)\n",
        "        plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "suh6Sjv68rY3",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(train_data_gen)\n",
        "show_batch(image_batch, label_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R_7hEfQrU_H",
        "colab_type": "text"
      },
      "source": [
        "এখন ডাটাটা CNN নেটওয়ার্ক ট্রেনিং করার জন্য ফুল রেডি । উপরের কোড টা প্রতিবার রান করলে দেখবেন ভিন্ন ভিন্ন ছবি আসতেছে । এর কারণ আমরা `shuffle=True` সেট করে দিয়েছি । যার কারণে প্রতিবার ডাটা লোড করার আগে ডাটা সাফল করে নিচ্ছে । এখন আমরা দেখব `tf.data` ব্যাবহার করে কিভাবে ইমেজ ডাটা লোড করা যায় । "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AxS1cLzM8mEp"
      },
      "source": [
        "## `tf.data` ব্যাবহার করে ইমেজ ডাটা লোড করা"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ylj9fgkamgWZ"
      },
      "source": [
        "ইমেজ ডাটা লোড করার ক্ষেত্রে `keras.preprocessing` ব্যাবহার করা সুবিধাজনক কিন্তু এটার কিছু সমস্যা আছে ।  \n",
        "\n",
        "- এটা `tf.data` থেকে সময় বেশি নেই । সময় কিরকম বেশি নেয় সটা আমরা নিচে দেখিয়েছি । \n",
        "- এটাতে প্রোগ্রামারের কন্ট্রোল তুলনামূলক ভাবে কম । \n",
        "- এটা টেন্সরফ্লোর সাথে পুরোপুরি ভাবে ইন্টিগ্রেটেড না । "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IIG5CPaULegg"
      },
      "source": [
        "To load the files as a `tf.data.Dataset` first create a dataset of the file paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lAkQp5uxoINu",
        "colab": {}
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "coORvEH-NGwc",
        "colab": {}
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "    print(type(f.numpy()), ' ', f.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "91CPfUUJ_8SZ"
      },
      "source": [
        "এখনে আমরা কিছু ফাংশন লিখব । `get_label` এই ফাংশনের কাজ এটাকে কোন ইমেজের ফুল পাথ দিলে সেখান থেকে ইমেজের লেবেল বের করে ।  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "arSQzIey-4D4",
        "colab": {}
      },
      "source": [
        "def get_label(file_path):\n",
        "    # convert the path to a list of path components\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    # print(parts)\n",
        "    # The second to last is the class-directory\n",
        "    return parts[-2] == CLASS_NAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlIyw-xbrU_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = b'/root/.keras/datasets/flower_photos/daisy/16482676953_5296227d40_n.jpg'\n",
        "tmp_label = get_label(file_path).numpy()\n",
        "print(tmp_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dvgYCJwrU_z",
        "colab_type": "text"
      },
      "source": [
        "`decode_img` এই ফাংশন কে `tf.io.read_file` দিয়ে ইমেজ ফাইল রিড করে পাঠায়া দিলে সে এটাকে `jpeg` তে ডিকোড করে । এবং শেষ মুল ইমেজ কে রিসাজ করে ফেলে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MGlq4IP4Aktb",
        "colab": {}
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHzn7yfrVAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = tf.io.read_file(file_path) # read image as string\n",
        "image = decode_img(image)\n",
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InC1AOB5rVAN",
        "colab_type": "text"
      },
      "source": [
        "`process_path` ফাংশন একটা ইমেজ পাথ কে প্রসেস করে `(img, label)` আকারে রিটার্ন করে ।  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xhBRgvNqRRe",
        "colab": {}
      },
      "source": [
        "def process_path(file_path):\n",
        "    label = get_label(file_path)\n",
        "    # load the raw data from the file as a string\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S9a5GpsUOBx8"
      },
      "source": [
        "`image, label` এই আকারে ডাটা বানানোর জন্য আমরা `Dataset.map` ব্যাবহার করব । একাধিক ইমেজ যাতে করে প্যারালালি লোড এবং প্রসেস করা যায় যায় এই জন্য আমরা `num_parallel_calls=AUTOTUNE)` ব্যাবহার করব । \n",
        "\n",
        "`tf.data.experimental.AUTOTUNE` এটা ডিফাইন করে আপনার কম্পিউটারে কাজ করার জন্য কয়টা প্রসেস ফাকা আছে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3SDhbo8lOBQv",
        "colab": {}
      },
      "source": [
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kxrl0lGdnpRz",
        "colab": {}
      },
      "source": [
        "for image, label in labeled_ds.take(1):\n",
        "    print(\"Image shape:\", image.numpy().shape)\n",
        "    print(\"Image label:\", label.numpy())\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vYGCgJuR_9Qp"
      },
      "source": [
        "## ট্রেনিং করানোর মৌলিক কিছু বিষয় "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wwZavzgsIytz"
      },
      "source": [
        "কোন মডেল এই ডাটা দিয়ে ট্রেনিং করার জন্য নিচের বিষয়গুলো করতে হবে । \n",
        "\n",
        "* ডাটা খুব ভালভাবে সাফল করতে হবে \n",
        "* টোটাল ডাটা থেকে ব্যাচ অনুসারে ডাটা নেয়া \n",
        "* এবং এই ব্যাচ ডাটা যত তাড়াতাড়ি সম্ভব ট্রেনিং জন্য প্রস্তুত করা \n",
        "\n",
        "উপরের ৩ টা ফিচার `tf.data` দিয়ে খুব সহজেই ইমপ্লিমেন্ট করা যায় । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZmZJx8ePw_5",
        "colab": {}
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "    # ছোট ডাটাসেটের জন্য `ds = ds.cache(cache)` দরকার নাই । কিন্তু ডাটাসেট যদি \n",
        "    # অনেক বড় হয় তাহলে RAM এ সব ডাটা একসাথে ধরবে না । তখন আমাদের কে HDD \n",
        "    # এর সাহায্য নিতে হবে । \n",
        "    if cache:\n",
        "        # যদি ডাটা অনেক বড় হয় তাহলে তাহলে আমরা ডাটাকে মেমরিতে না রেখে \n",
        "        # আমরা যে cache=যে পাথ দিব সেখানে ডাটা ক্যাশ করে রাখবে । \n",
        "        # নিচে এটারও আমরা একটা উদাহরণ দেখব । \n",
        "        if isinstance(cache, str):\n",
        "            # HDD এ ডাটা ক্যাশ করে রাখবে । \n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            # RAM এ ডাটা ক্যাশ করে রাখবে \n",
        "            ds = ds.cache()\n",
        "\n",
        "    # ডাটা আমরা সাফল করে নিচ্ছি \n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    \n",
        "    # ডাটাসেট অসংখ্যবার রিপিট হবে সেটা বলে দিলাম \n",
        "    ds = ds.repeat()\n",
        "\n",
        "    # BATCH_SIZE অনুসারে আমারা ডাটা নিয়ে নিচ্ছি \n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # যখন মডেল একটা ব্যাচ ডাটার উপর ট্রেনিং হতে থাকবে তখন পরবর্তী ব্যাচ আগে থেকেই প্রস্তুত করে রাখব \n",
        "    # যাতে করে মডেলের যখন নতুন ব্যাচ ডাটা দরকার তখন এসে অপেক্ষে করা না লাগে । \n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnR1nM0rVA6",
        "colab_type": "text"
      },
      "source": [
        "উপরের ফাংশন `ds.shuffle(buffer_size=shuffle_buffer_size)` তে `buffer_size` আসলে কি করতেছে । এটা যেটা করে সেটা হল, মনে করেন আপনার সব মিলে ১০ টা ডাটা আছে । এবং আপনি যদি `buffer_size=3` দেন তাহলে সেটা ১০ টা ডাটা থেকে ৩ টা ডাটা নিবে এবং আপনার `BATCH_SIZE` যদি ২ হয় তাহলে তাহলে সেই ৩ টা ডাটা থেকে ২ টা ডাটা নিবে । এখন আপনার বাফারে কিন্তু ১ টা ডাটা আছে । কারণ ২ টা ডাটা আপনি নিয়ে নিয়েছেন । বাফারে এই দুইটা ফাকা জায়গা পুরন হবে মুল ১০ টা ডটা থেকে নতুন দুইটা ডাটা নিয়ে । এটা সম্পর্কে আরও জানতে দেখেন <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\">shuffle</a>\n",
        "\n",
        "`ds.repeat()` এখনে ফাংশন কোন ভেলু দেয়া না হলে সেটা ইনফিনিট ভাবে ডাটা কে রিপিট করবে । কিন্তু ভেলু দিয়ে দিয়ে ভেলু অনুসারে রিপিট করবে । মনে করে আপনার ডাটাসেট এ ৩ টা ডাটা আছে । এই রকম `[1, 2, 3]` এখন আপনি যদি `ds.repeat(2)` দেন তাহলে ডাটা এই রকম হবে `[1, 2, 3, 1, 2, 3]` এটা কাজে লাগে যখন ডাটা শেষ হয়ে যায় কিন্তু আমরা ট্রেনিং প্রসেস চালাতে চাই । রিপিট ফাংশন সম্পর্কে আরও জানতে <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat\"> repeat </a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATzy2dFIrVA9",
        "colab_type": "text"
      },
      "source": [
        "আমাদের ফাংশন রেডি । এখন আমরা এটাকে ব্যাবহার করতে পারব । নিচের মত করে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-YKnrfAeZV10",
        "colab": {}
      },
      "source": [
        "train_ds = prepare_for_training(labeled_ds)\n",
        "\n",
        "image_batch, label_batch = next(iter(train_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UN_Dnl72YNIj",
        "colab": {}
      },
      "source": [
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UMVnoBcG_NlQ"
      },
      "source": [
        "## সময়  \n",
        "\n",
        "এখানে আমরা দেখব কোনটাতে কেমন সময় লাগে । প্রথমে আমরা একটা ফাংশন লিখি যেটা আমাদের কে এই ডাটাসেটের উপর কোনটা কোনটা কেমন সময় লাগতেছে সেটা হিসাব করে দিবে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_gFVe1rp_MYr",
        "colab": {}
      },
      "source": [
        "import time\n",
        "default_timeit_steps = 1000\n",
        "\n",
        "def timeit(ds, steps=default_timeit_steps):\n",
        "    start = time.time()\n",
        "    it = iter(ds)\n",
        "    for i in range(steps):\n",
        "        batch = next(it)\n",
        "        if i%10 == 0:\n",
        "            print('.',end='')\n",
        "    print()\n",
        "    end = time.time()\n",
        "\n",
        "    duration = end-start\n",
        "    print(\"{} batches: {} s\".format(steps, duration))\n",
        "    print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TYiOr4vdLcNX"
      },
      "source": [
        "এখন আমরা উপরের দুইটা ডাটা জেনারেটরে মধ্যে সময় হিসাব করি । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "85Yc-jZnVjvm",
        "colab": {}
      },
      "source": [
        "# `keras.preprocessing`\n",
        "timeit(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjouTJadRxyp",
        "colab": {}
      },
      "source": [
        "# `tf.data`\n",
        "timeit(train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZB2TjJR62BJ3"
      },
      "source": [
        "এখানে আমরা দেখতে পাচ্ছি দুইটার মধ্যে কত পার্থক্য । কিন্তু আমাদের মেমরি যদি কম হয় তাহলে এটা আমরা করতে পারব না । \n",
        "\n",
        "একবার প্রসেস করা ডাটা আমরা `.cache` এর মাধ্যমে জমা করে রাখব । পরের বার যখন একই ডাটার জন্য রিকুয়েস্ট করবে তখন আগে দেখবে ডাটা টা ক্যাশ এ আছে কি না । যদি ক্যাশ এ থাকে তাহলে সেটা রিটার্ন করবে । যদি ক্যাশ এ না থাকে তাহলে ডাটা কে প্রসেস করে ক্যাশ জমা রাখবে । যাতে পরবর্তী সময়ে সেটা ব্যাবহার করা যায় । \n",
        "\n",
        "ক্যাশ ব্যাবহার না করে দেখি কেমন সময় লাগে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oq1V854E2Nh4",
        "colab": {}
      },
      "source": [
        "uncached_ds = prepare_for_training(labeled_ds, cache=False)\n",
        "timeit(uncached_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-JCHymejWSPZ"
      },
      "source": [
        "যদি ডাটাসেট মেমরি তে ফিট না করে তাহলে আমরা ক্যাশ ডাটা কে একটা ফাইলে রাইট করে রাখব । এটা RAM এর মত ফাস্ট না হলেও `keras.preprocessing` থেকে অনেক ফাস্ট হবে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RqHFQFwxWNbu",
        "colab": {}
      },
      "source": [
        "# create a caches directory\n",
        "!mkdir caches\n",
        "\n",
        "filecache_ds = prepare_for_training(labeled_ds, cache=\"caches/flowers.tfcache\")\n",
        "timeit(filecache_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRVPzaIvrVB0",
        "colab_type": "text"
      },
      "source": [
        "আমরা `ls` করলে `flowers.tfcache` ফাইল দেখতে পারব । আমাদের ডাটাসেট যত বড় হবে এই ফাইলের সাইজ তত বড় হতে থাকবে । "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gxl3oo4rVB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!du -sh caches/\n",
        "print('*'*40)\n",
        "!ls -l caches/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX0r0nbHrVB6",
        "colab_type": "text"
      },
      "source": [
        "- মুল লেখা <a href=\"https://www.tensorflow.org/tutorials/load_data/images\"> Image data loading </a>\n",
        "- <a href=\"https://youtu.be/kVEOCfBy9uY?list=PLQY2H8rRoyvzIuB8rZXs7pfyjiSUs8Vza\"> TF inut pipeline  </a>\n",
        "- <a href=\"https://medium.com/analytics-vidhya/tensorflow-2-0-tf-data-api-eaa9889186cc\"> TensorFlow 2.0: tf.data API</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHEVFpC9t7s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}